{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install lifetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "from lifetimes import BetaGeoFitter,GammaGammaFitter\n",
    "\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from datetime import date\n",
    "import datetime\n",
    "import psycopg2\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "\n",
    "def start_cltv():\n",
    "\n",
    "        con=psycopg2.connect(dbname= 'dev', host='mantix-cluster.cgzkthavydhk.us-east-2.redshift.amazonaws.com', \n",
    "        port= '5439', user= 'mantix', password= 'Mantix123!')\n",
    "        cur = con.cursor()\n",
    "\n",
    "        orders_data = pd.read_sql(\"select * from cdp.orders_data;\",con)\n",
    "\n",
    "        orders_data=orders_data[(orders_data['tenant_id']=='TNB00001') & (orders_data['store_id']=='STOM000000001')]\n",
    "\n",
    "        orders_data = orders_data[~orders_data['status'].isin(['Abandoned','Errored','Pending','PendingReview','Cancelled','Null'])]\n",
    "\n",
    "        items_data = pd.read_sql(\"select * from cdp.items_data;\",con)\n",
    "\n",
    "        orders_data.order_number = orders_data.order_number.astype(int).astype(str)\n",
    "        items_data.order_number = items_data.order_number.astype(int).astype(str)\n",
    "\n",
    "        ord_cust = orders_data[['customer_account_id','fulfillment_date','order_number']]\n",
    "        items_df = items_data[['product_name','product_code','total','order_number','quantity']]\n",
    "\n",
    "        df =pd.merge(ord_cust,items_data[['product_name','product_code','total','order_number','quantity']],on=['order_number'],how='inner')\n",
    "\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        #df = df.dropna(subset=['customer_account_id','total','fulfillment_date'])\n",
    "\n",
    "        column_dict = {'order_number':'Invoice','product_code':'StockCode',\n",
    "                'quantity':'Quantity','fulfillment_date':'InvoiceDate',\n",
    "                'customer_account_id':'CustomerId','total':'TotalPrice'}\n",
    "\n",
    "        req_col = ['Invoice','InvoiceDate','CustomerId','TotalPrice']\n",
    "\n",
    "        df = df.rename(columns=column_dict)\n",
    "        df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "        df = df.fillna(df.mean())\n",
    "\n",
    "        today_date = datetime.datetime.now().time()\n",
    "        cltv_df = df.groupby('CustomerId').agg({'InvoiceDate': [lambda date: (date.max() - date.min()).days,\n",
    "                                                                lambda date: (pd.to_datetime('now')- date.min()).days],\n",
    "                                        'Invoice': lambda num: num.nunique(),\n",
    "                                        'TotalPrice': lambda TotalPrice: TotalPrice.sum()})\n",
    "\n",
    "        cltv_df.columns = cltv_df.columns.droplevel(0)\n",
    "        cltv_df.columns = ['recency', 'T', 'frequency', 'monetary']\n",
    "\n",
    "        #Expressing \"monetary value\" as average earnings per purchase\n",
    "        cltv_df[\"monetary\"] = cltv_df[\"monetary\"] / cltv_df[\"frequency\"]\n",
    "        # selection of monetary values greater than zero\n",
    "        cltv_df = cltv_df[cltv_df[\"monetary\"] > 0]\n",
    "        # Expression of \"recency \"and \"T\" in weekly terms\n",
    "        cltv_df[\"recency\"] = cltv_df[\"recency\"] / 7\n",
    "        cltv_df[\"T\"] = cltv_df[\"T\"] / 7\n",
    "        #frequency must be greater than 1.\n",
    "        cltv_df = cltv_df[(cltv_df['frequency'] > 1)]\n",
    "        cltv_df = cltv_df[cltv_df.recency < cltv_df['T']]\n",
    "\n",
    "        print(cltv_df.isna().sum())\n",
    "        #cltv_df.index = cltv_df.index.astype(float)\n",
    "        print('cltv : ',cltv_df.head())\n",
    "        cltv_df['CustomerId'] = cltv_df.index\n",
    "        cltv_df['env'] = 'prod'\n",
    "\n",
    "\n",
    "        ### Starting cltv model\n",
    "        cltv_prod = cltv_df.copy()\n",
    "        cltv_dev = pd.read_sql('SELECT * FROM cdp.cltv_support;',con)\n",
    "        cltv_dev = cltv_dev.rename(columns={'t':'T','customerid':'CustomerId'})\n",
    "        cltv_df = pd.concat([cltv_prod,cltv_dev])\n",
    "\n",
    "        bgf = BetaGeoFitter(penalizer_coef=0.001)\n",
    "        #setting up the model\n",
    "        bgf.fit(cltv_df['frequency'],\n",
    "                cltv_df['recency'],\n",
    "                cltv_df['T'])\n",
    "\n",
    "        cltv_df[\"expected_purc_6_month\"] = bgf.predict(4*6,\n",
    "                                                cltv_df['frequency'],\n",
    "                                                cltv_df['recency'],\n",
    "                                                cltv_df['T'])\n",
    "        cltv_df[\"expected_purc_12_month\"] = bgf.predict(4*12,\n",
    "                                                cltv_df['frequency'],\n",
    "                                                cltv_df['recency'],\n",
    "                                                cltv_df['T'])\n",
    "        cltv_df[\"expected_purc_24_month\"] = bgf.predict(4*24,\n",
    "                                                cltv_df['frequency'],\n",
    "                                                cltv_df['recency'],\n",
    "                                                cltv_df['T'])\n",
    "\n",
    "        cltv_df.index = cltv_df.CustomerId\n",
    "\n",
    "        ggf = GammaGammaFitter(penalizer_coef=0.01)\n",
    "        ggf.fit(cltv_df['frequency'], cltv_df['monetary'])\n",
    "\n",
    "        cltv_6_months = ggf.customer_lifetime_value(bgf,\n",
    "        cltv_df['frequency'],\n",
    "        cltv_df['recency'],\n",
    "        cltv_df['T'],\n",
    "        cltv_df['monetary'],\n",
    "        time=6, # 6 Months\n",
    "        freq=\"W\", # Frequency of T ,in this case it is 'weekly'\n",
    "        discount_rate=0.01)\n",
    "\n",
    "        cltv_12_months = ggf.customer_lifetime_value(bgf,\n",
    "        cltv_df['frequency'],\n",
    "        cltv_df['recency'],\n",
    "        cltv_df['T'],\n",
    "        cltv_df['monetary'],\n",
    "        time=12, # 6 Months\n",
    "        freq=\"W\", # Frequency of T ,in this case it is 'weekly'\n",
    "        discount_rate=0.01)\n",
    "\n",
    "        cltv_24_months = ggf.customer_lifetime_value(bgf,\n",
    "        cltv_df['frequency'],\n",
    "        cltv_df['recency'],\n",
    "        cltv_df['T'],\n",
    "        cltv_df['monetary'],\n",
    "        time=24, # 6 Months\n",
    "        freq=\"W\", # Frequency of T ,in this case it is 'weekly'\n",
    "        discount_rate=0.01)\n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "\n",
    "        cltv_6_months = cltv_6_months.reset_index()\n",
    "        cltv_6_months = cltv_6_months.rename(columns={'clv':'cltv_6M'})\n",
    "        cltv_6_months['scaled_cltv_6M'] = scaler.fit_transform(cltv_6_months[['cltv_6M']])\n",
    "\n",
    "        cltv_12_months = cltv_12_months.reset_index()\n",
    "        cltv_12_months = cltv_12_months.rename(columns={'clv':'cltv_12M'})\n",
    "        cltv_12_months['scaled_cltv_12M'] = scaler.fit_transform(cltv_12_months[['cltv_12M']])\n",
    "\n",
    "        cltv_24_months = cltv_24_months.reset_index()\n",
    "        cltv_24_months = cltv_24_months.rename(columns={'clv':'cltv_24M'})\n",
    "        cltv_24_months['scaled_cltv_24M'] = scaler.fit_transform(cltv_24_months[['cltv_24M']])\n",
    "\n",
    "\n",
    "        cltv_df = cltv_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        cltv_final = cltv_df.merge(cltv_6_months, on=\"CustomerId\", how=\"inner\")\n",
    "        cltv_final = cltv_final.merge(cltv_12_months, on=\"CustomerId\", how=\"inner\")\n",
    "        cltv_final = cltv_final.merge(cltv_24_months, on=\"CustomerId\", how=\"inner\")\n",
    "\n",
    "        cltv_final = cltv_final[cltv_final.CustomerId.isin(cltv_prod.CustomerId)]\n",
    "\n",
    "        req_col = ['CustomerId',\n",
    "                'cltv_6M',\n",
    "                'cltv_12M',\n",
    "                'cltv_24M',]\n",
    "\n",
    "        cltv_final=cltv_final[req_col]\n",
    "\n",
    "        cltv_final = cltv_final.groupby(['CustomerId']).median().reset_index()\n",
    "        cltv_final['tenant_id'] = 'TNB00001'\n",
    "        cltv_final['store_id'] = 'STOM000000001'\n",
    "        today_date = date.today()\n",
    "        cltv_final['create_dms'] = today_date\n",
    "        con.close()\n",
    "        return cltv_final\n",
    "\n",
    "def load_db(cltv_final):\n",
    "    con=psycopg2.connect(dbname= 'dev', host='mantix-cluster.cgzkthavydhk.us-east-2.redshift.amazonaws.com', \n",
    "    port= '5439', user= 'mantix', password= 'Mantix123!')\n",
    "    cur = con.cursor()\n",
    "\n",
    "    def drop_table(conn,table):\n",
    "        try:\n",
    "            query = f\"\"\"DROP TABLE IF EXISTS {table}\"\"\"\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "            print(f'Drop table {table} successfully')\n",
    "            cur.close()\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(\"Error: %s\" % error)\n",
    "            conn.rollback()\n",
    "            cur.close()\n",
    "            #return 1\n",
    "\n",
    "    def create_table(conn,table):\n",
    "        try:\n",
    "            query_col = \"\"\"(customer_account_id VARCHAR(1000),\n",
    "                cltv_6M FLOAT,cltv_12M FLOAT,\n",
    "                cltv_24M FLOAT,tenant_id VARCHAR(1000),store_id VARCHAR(1000),create_dms VARCHAR(1000))\"\"\"\n",
    "            query = f\"\"\"\n",
    "                    CREATE TABLE {table} \n",
    "                    \"\"\"+query_col\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(\"ROLLBACK\")\n",
    "            conn.commit()\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "            print(f'Successfully created the table {table}')\n",
    "            cur.close()\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(\"Error: %s\" % error)\n",
    "            conn.rollback()\n",
    "            cur.close()\n",
    "            return 1\n",
    "            \n",
    "    def single_insert(conn, insert_req):\n",
    "        \"\"\" Execute a single INSERT request \"\"\"\n",
    "        cursor = conn.cursor()\n",
    "        try:\n",
    "            cursor.execute(insert_req)\n",
    "            conn.commit()\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(\"Error: %s\" % error)\n",
    "            conn.rollback()\n",
    "            cursor.close()\n",
    "            return 1\n",
    "        cursor.close()\n",
    "        \n",
    "    def batch_insert(conn, batch_df):\n",
    "        # Create a cursor object from the connection\n",
    "        cursor = conn.cursor()\n",
    "        statment= f\"\"\"INSERT into {table}(customer_account_id,cltv_6M,cltv_12M,cltv_24M,tenant_id,store_id,create_dms) values(%s,%s,%s,%s,%s,%s,%s);\"\"\"\n",
    "        try:\n",
    "            # Execute the batch INSERT request\n",
    "            cursor.executemany(statment, batch_df)\n",
    "            # Commit the changes to the database\n",
    "            conn.commit()\n",
    "            print(\"Batch INSERT successful.\")\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            # Rollback the transaction in case of an error\n",
    "            conn.rollback()\n",
    "            print(\"Batch INSERT failed, Error:\", error)\n",
    "        finally:\n",
    "            # Close the cursor\n",
    "            cursor.close() \n",
    "        \n",
    "        \n",
    "    def insert_dataframe(final_df,conn,table):\n",
    "        batch_df=[]\n",
    "        for i in final_df.index:\n",
    "            current_tuple=(\n",
    "                        cltv_final.loc[i]['CustomerId'], \n",
    "                        cltv_final.loc[i]['cltv_6M'],\n",
    "                        cltv_final.loc[i]['cltv_12M'],\n",
    "                        cltv_final.loc[i]['cltv_24M'],\n",
    "                        str(cltv_final.loc[i]['tenant_id']),\n",
    "                        str(cltv_final.loc[i]['store_id']),\n",
    "                        str(cltv_final.loc[i]['create_dms'])\n",
    "                )\n",
    "            batch_df.append(current_tuple)\n",
    "            if (len(batch_df) == 500): \n",
    "                batch_insert(conn, batch_df)\n",
    "                batch_df=[]\n",
    "                print(\"Current index: {}, time: {}\".format(i, datetime.datetime.now()))\n",
    "            #endif\n",
    "        # Insert any remaining rows\n",
    "        if (len(batch_df) > 0):\n",
    "            batch_insert(conn,batch_df)\n",
    "        print('Successfully inserted dataframe into the table')\n",
    "        \n",
    "    table = 'cdp.cltv'\n",
    "    drop_table(con,table)\n",
    "    create_table(con,table)\n",
    "    startTime = datetime.datetime.now()\n",
    "    insert_dataframe(cltv_final,con,table)\n",
    "    print(\"Start: {}, Finish: {}\".format(startTime, datetime.datetime.now()))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # start cltv\n",
    "    cltv_final = start_cltv()\n",
    "    print(cltv_final.shape)\n",
    "\n",
    "    # load data into database\n",
    "    load_db(cltv_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_db(cltv_final):\n",
    "#     con=psycopg2.connect(dbname= 'dev', host='mantix-cluster.cgzkthavydhk.us-east-2.redshift.amazonaws.com', \n",
    "#     port= '5439', user= 'mantix', password= 'Mantix123!')\n",
    "#     cur = con.cursor()\n",
    "\n",
    "#     def drop_table(conn,table):\n",
    "#         try:\n",
    "#             query = f\"\"\"DROP TABLE IF EXISTS {table}\"\"\"\n",
    "#             cur = conn.cursor()\n",
    "#             cur.execute(query)\n",
    "#             conn.commit()\n",
    "#             print(f'Drop table {table} successfully')\n",
    "#             cur.close()\n",
    "#         except (Exception, psycopg2.DatabaseError) as error:\n",
    "#             print(\"Error: %s\" % error)\n",
    "#             conn.rollback()\n",
    "#             cur.close()\n",
    "#             #return 1\n",
    "\n",
    "#     def create_table(conn,table):\n",
    "#         try:\n",
    "#             query_col = \"\"\"(customer_account_id VARCHAR(1000),\n",
    "#                 cltv_6M FLOAT,cltv_12M FLOAT,\n",
    "#                 cltv_24M FLOAT,tenant_id VARCHAR(1000),store_id VARCHAR(1000),create_dms VARCHAR(1000))\"\"\"\n",
    "#             query = f\"\"\"\n",
    "#                     CREATE TABLE {table} \n",
    "#                     \"\"\"+query_col\n",
    "#             cur = conn.cursor()\n",
    "#             cur.execute(\"ROLLBACK\")\n",
    "#             conn.commit()\n",
    "#             cur.execute(query)\n",
    "#             conn.commit()\n",
    "#             print(f'Successfully created the table {table}')\n",
    "#             cur.close()\n",
    "#         except (Exception, psycopg2.DatabaseError) as error:\n",
    "#             print(\"Error: %s\" % error)\n",
    "#             conn.rollback()\n",
    "#             cur.close()\n",
    "#             return 1\n",
    "            \n",
    "#     def single_insert(conn, insert_req):\n",
    "#         \"\"\" Execute a single INSERT request \"\"\"\n",
    "#         cursor = conn.cursor()\n",
    "#         try:\n",
    "#             cursor.execute(insert_req)\n",
    "#             conn.commit()\n",
    "#         except (Exception, psycopg2.DatabaseError) as error:\n",
    "#             print(\"Error: %s\" % error)\n",
    "#             conn.rollback()\n",
    "#             cursor.close()\n",
    "#             return 1\n",
    "#         cursor.close()\n",
    "        \n",
    "#     def insert_dataframe(cltv_final,conn,table):\n",
    "#         for i in cltv_final.index:\n",
    "#             query = f\"\"\"\n",
    "#                     INSERT into {table}(customer_account_id,cltv_6M,cltv_12M,cltv_24M,tenant_id,store_id,create_dms) \n",
    "#                         values('%s',%s,%s,%s,%s,%s,%s);\n",
    "#                     \"\"\" % (cltv_final.loc[i]['CustomerId'], \n",
    "#                         cltv_final.loc[i]['cltv_6M'],\n",
    "                        \n",
    "#                         cltv_final.loc[i]['cltv_12M'],\n",
    "                        \n",
    "#                         cltv_final.loc[i]['cltv_24M'],\n",
    "                        \n",
    "#                         \"'\"+str(cltv_final.loc[i]['tenant_id'])+\"'\",\n",
    "#                         \"'\"+str(cltv_final.loc[i]['store_id'])+\"'\",\n",
    "#                          \"'\"+str(cltv_final.loc[i]['create_dms'])+\"'\")\n",
    "#             if i%50==0:\n",
    "#                 print(i,end=' ')\n",
    "#             single_insert(conn, query)\n",
    "#         conn.commit()\n",
    "#         print('\\nSuccessfully inserted dataframe into the table')\n",
    "        \n",
    "#     table = 'cdp.cltv'\n",
    "#     drop_table(con,table)\n",
    "#     create_table(con,table)\n",
    "#     insert_dataframe(cltv_final,con,table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
